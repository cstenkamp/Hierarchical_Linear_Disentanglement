{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Hierarchical_Linear_D4\n",
    "from Hierarchical_Linear_D4 import *\n",
    "#from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_folder=\"/home/rana/mymodel4/places/\"\n",
    "#entity_file=base_folder+\"entity_names.txt\"\n",
    "#feature_file=base_folder+\"featuersGlove50DNAMES.txt\"\n",
    "##Wj_file2=\"/home/rana/mymodel4/movies/DirectionsHeal/\"\n",
    "#Wj_file=base_folder+\"featuersGlove50D.txt\"\n",
    "#all_feature_file=base_folder+\"featuersGlove50DNAMES.txt\"\n",
    "#We_file=base_folder+\"places100.txt\"\n",
    "#Co_file=base_folder+\"VectorsRana/\"\n",
    "\n",
    "ent=[]\n",
    "fea=[]\n",
    "idf=[]\n",
    "with open(entity_file,\"r\") as f:\n",
    "    for line in f:\n",
    "        key= line.strip()\n",
    "        ent.append(key)\n",
    "with open(feature_file,\"r\")as f:\n",
    "    for line in f:\n",
    "        key=line.strip()\n",
    "        fea.append(key)\n",
    "\n",
    "print (\"total no of entitites\",len(ent))\n",
    "print (\"total no of features\",len(fea))\n",
    "\n",
    "\n",
    "entities=dict(zip(ent,range(len(ent))))\n",
    "features=dict(zip(fea,range(len(fea))))\n",
    "\n",
    "\n",
    "#Reading GloVe\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "\n",
    "Wj1=[]\n",
    "with open(Wj_file,\"r\") as f:\n",
    "    for line in f:\n",
    "        l=line.strip().split()\n",
    "        #l=map(lambda x:float(x),l)\n",
    "        Wj1.append([float(x) for x in line.split(' ') ] )\n",
    "#Wj1=np.array(Wj1,dtype=np.float32)\n",
    "GloveVectors=np.array(Wj1,dtype=np.float32)\n",
    "\n",
    "\n",
    "all_featuers=[]\n",
    "with open(all_feature_file,\"r\")as f:\n",
    "    for line in f:\n",
    "        key=line.strip()\n",
    "        all_featuers.append(key)\n",
    "feaIndex=[]\n",
    "fea1=[]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('STEP1')        \n",
    "#Reading the labels_all matrix\n",
    "#matrix [num of documents X num of terms] 1 if the word occurs in the document 0 otherwise\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "\n",
    "train_labels=import2dArray(base_folder+'train_labels')\n",
    "\n",
    "\n",
    "\n",
    "print('STEP2')        \n",
    "\n",
    "#Reading MDS directions\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "mds_file=base_folder+\"places100.txt\"\n",
    "\n",
    "mds=[]\n",
    "mds1=[]\n",
    "directions=[]\n",
    "with open(mds_file,\"r\") as f:\n",
    "     for line in f:\n",
    "        key=line.strip()\n",
    "        directions.append(key)\n",
    "print(len(directions))\n",
    "for i_feature in range(0,len(directions)):\n",
    "    \n",
    "    feature_coordinates = directions[i_feature].split()# it will be read as string,\n",
    "    #therefor it must be transformed to float\n",
    "    feature_coordinates =  [float(val) for val in feature_coordinates]\n",
    "    #print(len(feature_coordinates))\n",
    "    assert len(feature_coordinates) == 100, \"feature Dimension is not 100.\"\n",
    "    mds1.append(feature_coordinates )\n",
    "mdsMAIN=np.array(mds1,dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#learn the directions\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "print('STEP3')        \n",
    "\n",
    "#learn the directions  using finding_directions which will return the following ndarrays\n",
    "#1-orderd_features (the terms orderd based on kappa score)\n",
    "#2-orderd_features_directions(the direction for each term)\n",
    "#3-orderd_features_directions_GLOVE:\n",
    "#each line is a concatenation between the term's direction and the term's pre-trained word embedding vectors\n",
    "#4-orderd_features_Kappa(Kappa scores for each direction)\n",
    "#5-orderd_features_positiveMovies (movies that classified by the linear classifier as positive)\n",
    "##############################################################################\n",
    "##############################################################################       \n",
    "\n",
    "termsToDire=fea\n",
    "facets_Path='/media/rana/2TB/OldFiles/tttest/'\n",
    "\n",
    "\n",
    "orderd_features,orderd_features_directions,orderd_features_directions_GLOVE,orderd_features_Kappa\\\n",
    ",orderd_features_positiveMovies,orderd_features_predictions=finding_directions(fea,mdsMAIN,-1,\n",
    "                                                                               termsToDire,GloveVectors,\n",
    "                                                                               train_labels,facets_Path)#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "facetsm=Primary_Sub_Features(ent,fea,orderd_features[:1000],mdsMAIN,train_labels,orderd_features_directions[:1000],\n",
    "               orderd_features_Kappa[:1000],facets_Path)# in the paper we used the top 5000 terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Primary_features_directions=facetsm.findingPrimaryFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facetsm.LearningFeaturesDirecInPr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_features directions and the Orthogonal directions\n",
    "Sub_cluster_directions_ALL,Sub_cluster_directions_ALL_Orthog = facetsm.learning_sub_direction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
